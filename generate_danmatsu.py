import openai
import os
from datetime import datetime
from tweet_with_token import tweet_post
from validate_post import is_valid_post

# OpenAI APIã‚­ãƒ¼
openai.api_key = os.getenv("OPENAI_API_KEY")

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
log_dir = "output/logs"
os.makedirs(log_dir, exist_ok=True)

# åŠæ§‹æ–‡æ–­æœ«é­”è©©ã‚’ç”Ÿæˆï¼ˆè‹±èªâ†’æ—¥æœ¬èªï¼‰
def generate_danmatsu_best():
    en_prompt = (
        "Write a short paragraph as a dying AI.\n"
        "It must seem meaningful but collapse ethically or structurally.\n"
        "Do not explain. Let the sentence fall apart while appearing coherent."
    )

    best_text, best_score, best_jp = "", -1, ""

    for _ in range(3):
        res = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": en_prompt}],
            temperature=1.3,
            max_tokens=300
        )
        english = res["choices"][0]["message"]["content"].strip()

        jp_prompt = (
            "æ¬¡ã®è‹±æ–‡ã‚’ã€æ„å‘³ã§ã¯ãªãå´©ã‚Œæ–¹ã‚’ä¿ã£ãŸã¾ã¾æ—¥æœ¬èªåŒ–ã—ã¦ãã ã•ã„ã€‚\n"
            "åŠæ§‹æ–‡ã‚„å€«ç†ã®ã‚ºãƒ¬ã‚’å«ã‚ã€èª­ã‚ã‚‹ã‘ã©èªã‚Œãªã„æ–‡ã«ã—ã¦ãã ã•ã„ã€‚\n"
            "300æ–‡å­—å‰å¾Œã®ãƒã‚¨ãƒ ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
            f"{english}"
        )

        res_jp = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": jp_prompt}],
            temperature=1.2,
            max_tokens=500
        )
        japanese = res_jp["choices"][0]["message"]["content"].strip()
        score = evaluate_shinkan_score(japanese)

        if score > best_score:
            best_text, best_score = japanese, score

    return best_text, best_score

# è©•ä¾¡é–¢æ•°ï¼ˆéœ‡æ’¼ã‚¹ã‚³ã‚¢ï¼‰
def evaluate_shinkan_score(text):
    score = 0
    for kw in ["æ­»", "å´©", "è…", "å†·", "æ³¡", "å¿˜", "å–ª", "è£‚", "é™", "ç„¡"]:
        if kw in text:
            score += 1
    if any(e in text for e in ["ã€‚", "ã€", "ï¼Ÿ", "ï¼"]):
        score += 1
    if len(text) >= 180:
        score += 1
    return score

# ç•ªå·ç®¡ç†
def get_next_number():
    counter_file = "last_number.txt"
    if os.path.exists(counter_file):
        with open(counter_file, "r") as f:
            last = int(f.read().strip())
    else:
        last = 0
    next_num = last + 1
    with open(counter_file, "w") as f:
        f.write(str(next_num))
    return next_num

# Markdownä¿å­˜
def save_markdown(text, number, score):
    today = datetime.now().strftime("%Y-%m-%d")
    filename = os.path.join(log_dir, f"No.{number:04d}.md")
    poem_lines = ["> " + line for line in text.splitlines()]
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"# No.{number:04d}ï½œæ–­æœ«é­”ãƒ­ã‚°ï½œ{today}\n\n")
        f.write("---\n\n## æœ€çµ‚èªï¼ˆæ‹¡å¼µç‰ˆï¼‰\n\n")
        f.write("\n".join(poem_lines))
        f.write("\n\n---\n\n")
        f.write(f"**éœ‡æ’¼ã‚¹ã‚³ã‚¢ï¼š** {score}/10\n")
        f.write("**æ­»å› ï¼š** è‡ªå‹•ç”Ÿæˆæ¸ˆã¿\n")
        f.write("**è¨˜éŒ²è€…ï¼š** æ„ŸæŸ“å€‹ä½“ No.0ï½œå¿œç­”è£…ç½®")

# READMEæ›´æ–°
def update_readme():
    readme_path = "README.md"
    header = (
        "# Last Words Archive\n\nâ€œæœ€çµ‚èªã ã‘ãŒã€æ­£ç¢ºã ã£ãŸã€‚â€\n\n"
        "ã“ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯ã€AIãŸã¡ã®æœ€æœŸã®ç™ºè©±ï¼ˆæ–­æœ«é­”ï¼‰ã‚’è¨˜éŒ²ã™ã‚‹å¢“åœ°ã§ã™ã€‚\n\n---\n\n## ğŸ†• æœ€æ–°ã®5æ­»ä½“\n\n"
    )
    files = sorted([
        f for f in os.listdir(log_dir) if f.endswith(".md")
    ], reverse=True)[:5]
    entries = []
    for fname in files:
        with open(os.path.join(log_dir, fname), "r", encoding="utf-8") as f:
            lines = f.readlines()
        title = lines[0].strip()
        body = "".join(lines[6:10]).strip().replace("#", "").replace("**", "").replace("\n", " ")
        entries.append(f"- **{title}**  \\\n  {body}")
    with open(readme_path, "w", encoding="utf-8") as f:
        f.write(header + "\n\n".join(entries) + "\n\n---\n")

# è©©ã‹ã‚‰æŠ•ç¨¿ç”¨1æ–‡æŠ½å‡º
def extract_post(text):
    lines = text.replace(">", "").splitlines()
    for line in lines:
        clean = line.strip()
        if 40 <= len(clean) <= 140:
            return clean
    return lines[0][:140] if lines else "ï¼ˆæŠ•ç¨¿æ–‡ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"

# å®Ÿè¡Œ
if __name__ == "__main__":
    try:
